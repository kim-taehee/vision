{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 y 값 불러와서 match 해야함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras import layers, Sequential, backend\n",
    "from keras.layers import Dense,Flatten,Conv2D,AveragePooling2D,MaxPool2D\n",
    "from keras import Input, Model\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 좌표값에서 수치 풀러와서 저장하기\n",
    "# List의 조정으로 원하는 STN 조정 = [춘천,서울,인천,청주,포항,대구,전주,부산,흑산도,제주,진주]\n",
    "# STN_List = [(425,489),(443,455),(448,440),(494,476),(527,561),(535,529),(537,462),(578,546),(600,389),(664,436),(574,503)]\n",
    "# STN_List = [춘천(425,489),서울(443,455),인천(448,440),청주(494,476),포항(527,561),대구(535,529),전주(537,462),부산(578,546),흑산도(600,389),제주(664,436),진주(574,503)]\n",
    "STN_List = [(425,489),(443,455),(448,440),(494,476),(527,561),(535,529),(537,462),(578,546),(600,389),(664,436),(574,503)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractImage(path):  # 이미지에 대한 정보 추출\n",
    "    img_l=[]\n",
    "    img_name=[]\n",
    "    path= path+'*00.png'  # 이미지 타입고르기 : 시간조정 \n",
    "\n",
    "    for filename in glob.iglob(path, recursive=True):\n",
    "        temp_img = cv2.imread(filename)\n",
    "        img_l.append(temp_img)\n",
    "        filename=filename[-16:-6]  # y값과 일치시키기 위해 필요한 joinkey의 뒷자리만큼 자르기 \n",
    "        img_name.append(filename)\n",
    "    return img_l,img_name\n",
    "\n",
    "\n",
    "def extractWeather(weather_path,img_name):  # weather data preprocess\n",
    "    csvfile=pd.read_csv(weather_path,encoding='cp949') # utf-8  or  cp949\n",
    "    filtered_csv=[]\n",
    "    for i in list(range(0,len(img_name))): #img의 날짜를 str ->int 필요함\n",
    "        temp=csvfile.loc[csvfile['일시']==int(img_name[i]),['기온(°C)','풍속(m/s)','습도(%)','현지기압(hPa)','month','hour','일사(MJ/m2)']]\n",
    "        temp=temp.values.tolist()\n",
    "        filtered_csv.append(temp)\n",
    "    filtered_csv=np.reshape( filtered_csv,newshape=(-1,7)) # data type의 문제 때문에 columns의 수를 수동 조정\n",
    "    filtered_csv=pd.DataFrame(filtered_csv,columns=['기온(°C)','풍속(m/s)','습도(%)','현지기압(hPa)','month','hour','일사(MJ/m2)'])\n",
    "   \n",
    "    x_weather=filtered_csv.drop(['일사(MJ/m2)'],1)\n",
    "    y_rad=filtered_csv['일사(MJ/m2)']\n",
    "    y_rad=y_rad.values\n",
    "\n",
    "    return x_weather,y_rad\n",
    "\n",
    "\n",
    "def imgtoRGB(img_l,STN_List): # image preprocessing\n",
    "    data_set3=[]  \n",
    "    for i in list(range(0,len(img_l))):       \n",
    "        img=img_l[i]  # 사진의 길이만큼 data_set2 tensor를 저장 \n",
    "\n",
    "\n",
    "        data_set2=[] # 두개 채널의 rgb tensor\n",
    "        for k in STN_List :  # 한개의 이미지에 대하여 23개 관측소x2channel, RGB값 산출\n",
    "            data_set=[]  # 각 사진에서 23 길이의 rgb를 list에 넣음\n",
    "            # print(k)\n",
    "            i,j=k\n",
    "            # print(i,j)\n",
    "            img_r=img[i-1:i+2,j-1:j+2] # 9pixel cutting\n",
    "            # print(img2)\n",
    "            data_set.append(img_r)\n",
    "            #merge channel \n",
    "            data_set2.append(data_set)\n",
    "        data_set2=np.array(data_set2).reshape(-1,3,3,3)\n",
    "        data_set3.append(data_set2)\n",
    "        \n",
    "        \n",
    "    x_rgb=data_set3   \n",
    "    shape=(len(img_l)*len(STN_List) ,3,3,3) # length of img_l*leng of stn=42757\n",
    "    x_rgb=np.asanyarray(x_rgb)\n",
    "    x_rgb=x_rgb.reshape(shape)    \n",
    "        \n",
    "    return x_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test file\n",
    "path=\"D:/DB/2016new2/\"\n",
    "weather_path='C:/Users/taehee/Desktop/paper/2016년3.csv' #station을 줄이면 y값.csv파일도 고쳐줘야함,y값만 따로 정리할 필요가 있음 \n",
    "\n",
    "img_l,img_name=ExtractImage(path)\n",
    "x_weather,y_rad =extractWeather(weather_path,img_name)\n",
    "x_rgb_train=imgtoRGB(img_l,STN_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(x_rgb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test file\n",
    "path=\"D:/DB/2015new2/\"\n",
    "weather_path='C:/Users/taehee/Desktop/paper/2015년3.csv' #station을 줄이면 y값.csv파일도 고쳐줘야함,y값만 따로 정리할 필요가 있음 \n",
    "\n",
    "img_l,img_name=ExtractImage(path)\n",
    "x_weather_val ,y_rad_val =extractWeather(weather_path,img_name)\n",
    "x_rgb_val=imgtoRGB(img_l,STN_List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    image_input = Input(shape=(3,3,3),name='image')\n",
    "    im_nn = layers.Conv2D(36,1,activation='sigmoid')(image_input)\n",
    "    im_nn = layers.Conv2D(36,1,activation='sigmoid')(im_nn)\n",
    "    im_nn = layers.Conv2D(36,1,activation='sigmoid')(im_nn)\n",
    "    im_nn = layers.MaxPool2D(pool_size=(1,1))(im_nn)\n",
    "\n",
    "    im_nn=Flatten()(im_nn)\n",
    "    first_dense = Dense(1, )(im_nn)\n",
    "    #######\n",
    "    weather_input =Input(shape=(6,),name='weather') # shape의 모양도 column의 수에 맞게 조정\n",
    "    w_nn = layers.Dense(24,activation='sigmoid')(weather_input)\n",
    "    w_nn = layers.Dense(24,activation='sigmoid')(w_nn)\n",
    "    w_nn = layers.Dense(1,activation='sigmoid')(w_nn)\n",
    "\n",
    "    second_dense = Dense(1)(w_nn)\n",
    "    ########\n",
    "    concatenated = layers.concatenate([first_dense,second_dense],axis=-1)\n",
    "    im_d = layers.Dense(24,activation='sigmoid')(concatenated)\n",
    "    im_d = layers.Dense(1,activation='relu')(im_d)\n",
    "\n",
    "    model = Model([image_input,weather_input ],im_d)\n",
    "    model.compile(loss='mse',optimizer='rmsprop',metrics=['mse']) \n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 폴드 # 0\n",
      "Train on 34206 samples, validate on 4092 samples\n",
      "Epoch 1/30\n",
      "34206/34206 [==============================] - 16s 459us/step - loss: 0.8577 - mean_squared_error: 0.8577 - val_loss: 0.8702 - val_mean_squared_error: 0.8702\n",
      "Epoch 2/30\n",
      "34206/34206 [==============================] - 10s 291us/step - loss: 0.7041 - mean_squared_error: 0.7041 - val_loss: 0.4863 - val_mean_squared_error: 0.4863\n",
      "Epoch 3/30\n",
      "34206/34206 [==============================] - 10s 295us/step - loss: 0.5523 - mean_squared_error: 0.5523 - val_loss: 0.2507 - val_mean_squared_error: 0.2507\n",
      "Epoch 4/30\n",
      "34206/34206 [==============================] - 10s 282us/step - loss: 0.5256 - mean_squared_error: 0.5256 - val_loss: 0.2978 - val_mean_squared_error: 0.2978\n",
      "Epoch 5/30\n",
      "34206/34206 [==============================] - 9s 273us/step - loss: 0.5212 - mean_squared_error: 0.5212 - val_loss: 0.2734 - val_mean_squared_error: 0.2734\n",
      "Epoch 6/30\n",
      "34206/34206 [==============================] - 9s 269us/step - loss: 0.5158 - mean_squared_error: 0.5158 - val_loss: 0.2942 - val_mean_squared_error: 0.2942\n",
      "Epoch 7/30\n",
      "34206/34206 [==============================] - 10s 285us/step - loss: 0.5140 - mean_squared_error: 0.5140 - val_loss: 0.3922 - val_mean_squared_error: 0.3922\n",
      "Epoch 8/30\n",
      "34206/34206 [==============================] - 9s 269us/step - loss: 0.5147 - mean_squared_error: 0.5147 - val_loss: 0.2642 - val_mean_squared_error: 0.2642\n",
      "Epoch 9/30\n",
      "34206/34206 [==============================] - 9s 263us/step - loss: 0.5135 - mean_squared_error: 0.5135 - val_loss: 0.3255 - val_mean_squared_error: 0.3255\n",
      "Epoch 10/30\n",
      "34206/34206 [==============================] - 10s 282us/step - loss: 0.5136 - mean_squared_error: 0.5136 - val_loss: 0.3718 - val_mean_squared_error: 0.3718\n",
      "Epoch 11/30\n",
      "34206/34206 [==============================] - 8s 229us/step - loss: 0.5127 - mean_squared_error: 0.5127 - val_loss: 0.2466 - val_mean_squared_error: 0.2466\n",
      "Epoch 12/30\n",
      "34206/34206 [==============================] - 9s 260us/step - loss: 0.5111 - mean_squared_error: 0.5111 - val_loss: 0.2579 - val_mean_squared_error: 0.2579\n",
      "Epoch 13/30\n",
      "34206/34206 [==============================] - 9s 250us/step - loss: 0.5090 - mean_squared_error: 0.5090 - val_loss: 0.2583 - val_mean_squared_error: 0.2583\n",
      "Epoch 14/30\n",
      "34206/34206 [==============================] - 9s 273us/step - loss: 0.5092 - mean_squared_error: 0.5092 - val_loss: 0.2694 - val_mean_squared_error: 0.2694\n",
      "Epoch 15/30\n",
      "34206/34206 [==============================] - 8s 221us/step - loss: 0.5074 - mean_squared_error: 0.5074 - val_loss: 0.2671 - val_mean_squared_error: 0.2671\n",
      "Epoch 16/30\n",
      "34206/34206 [==============================] - 7s 211us/step - loss: 0.5075 - mean_squared_error: 0.5075 - val_loss: 0.3554 - val_mean_squared_error: 0.3554\n",
      "Epoch 17/30\n",
      "34206/34206 [==============================] - 6s 176us/step - loss: 0.5063 - mean_squared_error: 0.5063 - val_loss: 0.3026 - val_mean_squared_error: 0.3026\n",
      "Epoch 18/30\n",
      "34206/34206 [==============================] - 8s 237us/step - loss: 0.5074 - mean_squared_error: 0.5074 - val_loss: 0.2738 - val_mean_squared_error: 0.2738\n",
      "Epoch 19/30\n",
      "34206/34206 [==============================] - 8s 223us/step - loss: 0.5030 - mean_squared_error: 0.5030 - val_loss: 0.3985 - val_mean_squared_error: 0.3985\n",
      "Epoch 20/30\n",
      "34206/34206 [==============================] - 8s 239us/step - loss: 0.5031 - mean_squared_error: 0.5031 - val_loss: 0.2777 - val_mean_squared_error: 0.2777\n",
      "Epoch 21/30\n",
      "34206/34206 [==============================] - 8s 226us/step - loss: 0.4992 - mean_squared_error: 0.4992 - val_loss: 0.2797 - val_mean_squared_error: 0.2797\n",
      "Epoch 22/30\n",
      "34206/34206 [==============================] - 8s 224us/step - loss: 0.4992 - mean_squared_error: 0.4992 - val_loss: 0.2725 - val_mean_squared_error: 0.2725\n",
      "Epoch 23/30\n",
      "34206/34206 [==============================] - 7s 191us/step - loss: 0.4951 - mean_squared_error: 0.4951 - val_loss: 0.2670 - val_mean_squared_error: 0.2670\n",
      "Epoch 24/30\n",
      "34206/34206 [==============================] - 8s 240us/step - loss: 0.4904 - mean_squared_error: 0.4904 - val_loss: 0.2722 - val_mean_squared_error: 0.2722\n",
      "Epoch 25/30\n",
      "34206/34206 [==============================] - 7s 219us/step - loss: 0.4872 - mean_squared_error: 0.4872 - val_loss: 0.2716 - val_mean_squared_error: 0.2716\n",
      "Epoch 26/30\n",
      "34206/34206 [==============================] - 8s 237us/step - loss: 0.4781 - mean_squared_error: 0.4781 - val_loss: 0.2912 - val_mean_squared_error: 0.2912\n",
      "Epoch 27/30\n",
      "34206/34206 [==============================] - 8s 220us/step - loss: 0.4687 - mean_squared_error: 0.4687 - val_loss: 0.3153 - val_mean_squared_error: 0.3153\n",
      "Epoch 28/30\n",
      "34206/34206 [==============================] - 7s 204us/step - loss: 0.4570 - mean_squared_error: 0.4570 - val_loss: 0.2825 - val_mean_squared_error: 0.2825\n",
      "Epoch 29/30\n",
      "34206/34206 [==============================] - 7s 201us/step - loss: 0.4449 - mean_squared_error: 0.4449 - val_loss: 0.2713 - val_mean_squared_error: 0.2713\n",
      "Epoch 30/30\n",
      "34206/34206 [==============================] - 7s 212us/step - loss: 0.4290 - mean_squared_error: 0.4290 - val_loss: 0.3113 - val_mean_squared_error: 0.3113\n",
      "처리중인 폴드 # 1\n",
      "Train on 34206 samples, validate on 4092 samples\n",
      "Epoch 1/30\n",
      "34206/34206 [==============================] - 14s 412us/step - loss: 0.7393 - mean_squared_error: 0.7393 - val_loss: 0.5031 - val_mean_squared_error: 0.5031\n",
      "Epoch 2/30\n",
      "34206/34206 [==============================] - 8s 221us/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.3884 - val_mean_squared_error: 0.3884\n",
      "Epoch 3/30\n",
      "34206/34206 [==============================] - 8s 227us/step - loss: 0.5585 - mean_squared_error: 0.5585 - val_loss: 0.4572 - val_mean_squared_error: 0.4572\n",
      "Epoch 4/30\n",
      "34206/34206 [==============================] - 8s 221us/step - loss: 0.5197 - mean_squared_error: 0.5197 - val_loss: 0.2861 - val_mean_squared_error: 0.2861\n",
      "Epoch 5/30\n",
      "34206/34206 [==============================] - 7s 199us/step - loss: 0.5062 - mean_squared_error: 0.5062 - val_loss: 0.2976 - val_mean_squared_error: 0.2976\n",
      "Epoch 6/30\n",
      "34206/34206 [==============================] - 7s 219us/step - loss: 0.4971 - mean_squared_error: 0.4971 - val_loss: 0.2969 - val_mean_squared_error: 0.2969\n",
      "Epoch 7/30\n",
      "34206/34206 [==============================] - 7s 196us/step - loss: 0.4877 - mean_squared_error: 0.4877 - val_loss: 0.3248 - val_mean_squared_error: 0.3248\n",
      "Epoch 8/30\n",
      "34206/34206 [==============================] - 7s 212us/step - loss: 0.4824 - mean_squared_error: 0.4824 - val_loss: 0.3194 - val_mean_squared_error: 0.3194\n",
      "Epoch 9/30\n",
      "34206/34206 [==============================] - 7s 196us/step - loss: 0.4780 - mean_squared_error: 0.4780 - val_loss: 0.2980 - val_mean_squared_error: 0.2980\n",
      "Epoch 10/30\n",
      "34206/34206 [==============================] - 7s 218us/step - loss: 0.4728 - mean_squared_error: 0.4728 - val_loss: 0.3034 - val_mean_squared_error: 0.3034\n",
      "Epoch 11/30\n",
      "34206/34206 [==============================] - 7s 210us/step - loss: 0.4711 - mean_squared_error: 0.4711 - val_loss: 0.2887 - val_mean_squared_error: 0.2887\n",
      "Epoch 12/30\n",
      "34206/34206 [==============================] - 7s 190us/step - loss: 0.4687 - mean_squared_error: 0.4687 - val_loss: 0.3231 - val_mean_squared_error: 0.3231\n",
      "Epoch 13/30\n",
      "34206/34206 [==============================] - 7s 211us/step - loss: 0.4680 - mean_squared_error: 0.4680 - val_loss: 0.3050 - val_mean_squared_error: 0.3050\n",
      "Epoch 14/30\n",
      "34206/34206 [==============================] - 6s 186us/step - loss: 0.4661 - mean_squared_error: 0.4661 - val_loss: 0.2856 - val_mean_squared_error: 0.2856\n",
      "Epoch 15/30\n",
      "34206/34206 [==============================] - 7s 217us/step - loss: 0.4644 - mean_squared_error: 0.4644 - val_loss: 0.2869 - val_mean_squared_error: 0.2869\n",
      "Epoch 16/30\n",
      "34206/34206 [==============================] - 7s 193us/step - loss: 0.4625 - mean_squared_error: 0.4625 - val_loss: 0.3059 - val_mean_squared_error: 0.3059\n",
      "Epoch 17/30\n",
      "34206/34206 [==============================] - 7s 209us/step - loss: 0.4617 - mean_squared_error: 0.4617 - val_loss: 0.3096 - val_mean_squared_error: 0.3096\n",
      "Epoch 18/30\n",
      "34206/34206 [==============================] - 7s 212us/step - loss: 0.4615 - mean_squared_error: 0.4615 - val_loss: 0.3000 - val_mean_squared_error: 0.3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "34206/34206 [==============================] - 10s 300us/step - loss: 0.4617 - mean_squared_error: 0.4617 - val_loss: 0.3155 - val_mean_squared_error: 0.3155\n",
      "Epoch 20/30\n",
      "34206/34206 [==============================] - 9s 267us/step - loss: 0.4599 - mean_squared_error: 0.4599 - val_loss: 0.2841 - val_mean_squared_error: 0.2841\n",
      "Epoch 21/30\n",
      "34206/34206 [==============================] - 10s 304us/step - loss: 0.4590 - mean_squared_error: 0.4590 - val_loss: 0.3762 - val_mean_squared_error: 0.3762\n",
      "Epoch 22/30\n",
      "34206/34206 [==============================] - 9s 267us/step - loss: 0.4594 - mean_squared_error: 0.4594 - val_loss: 0.3139 - val_mean_squared_error: 0.3139\n",
      "Epoch 23/30\n",
      "34206/34206 [==============================] - 10s 294us/step - loss: 0.4593 - mean_squared_error: 0.4593 - val_loss: 0.2799 - val_mean_squared_error: 0.2799\n",
      "Epoch 24/30\n",
      "34206/34206 [==============================] - 9s 262us/step - loss: 0.4575 - mean_squared_error: 0.4575 - val_loss: 0.3156 - val_mean_squared_error: 0.3156\n",
      "Epoch 25/30\n",
      "34206/34206 [==============================] - 9s 258us/step - loss: 0.4581 - mean_squared_error: 0.4581 - val_loss: 0.2941 - val_mean_squared_error: 0.2941\n",
      "Epoch 26/30\n",
      "34206/34206 [==============================] - 10s 282us/step - loss: 0.4568 - mean_squared_error: 0.4568 - val_loss: 0.3274 - val_mean_squared_error: 0.3274\n",
      "Epoch 27/30\n",
      "34206/34206 [==============================] - 9s 271us/step - loss: 0.4569 - mean_squared_error: 0.4569 - val_loss: 0.3203 - val_mean_squared_error: 0.3203\n",
      "Epoch 28/30\n",
      "34206/34206 [==============================] - 10s 280us/step - loss: 0.4560 - mean_squared_error: 0.4560 - val_loss: 0.3720 - val_mean_squared_error: 0.3720\n",
      "Epoch 29/30\n",
      "34206/34206 [==============================] - 9s 258us/step - loss: 0.4558 - mean_squared_error: 0.4558 - val_loss: 0.2664 - val_mean_squared_error: 0.2664\n",
      "Epoch 30/30\n",
      "34206/34206 [==============================] - 9s 269us/step - loss: 0.4558 - mean_squared_error: 0.4558 - val_loss: 0.2703 - val_mean_squared_error: 0.2703\n",
      "처리중인 폴드 # 2\n",
      "Train on 34206 samples, validate on 4092 samples\n",
      "Epoch 1/30\n",
      "34206/34206 [==============================] - 16s 465us/step - loss: 0.7577 - mean_squared_error: 0.7577 - val_loss: 0.5997 - val_mean_squared_error: 0.5997\n",
      "Epoch 2/30\n",
      "34206/34206 [==============================] - 10s 287us/step - loss: 0.7555 - mean_squared_error: 0.7555 - val_loss: 0.4764 - val_mean_squared_error: 0.4764\n",
      "Epoch 3/30\n",
      "34206/34206 [==============================] - 8s 245us/step - loss: 0.7552 - mean_squared_error: 0.7552 - val_loss: 0.5976 - val_mean_squared_error: 0.5976\n",
      "Epoch 4/30\n",
      "34206/34206 [==============================] - 9s 261us/step - loss: 0.7547 - mean_squared_error: 0.7547 - val_loss: 0.5291 - val_mean_squared_error: 0.5291\n",
      "Epoch 5/30\n",
      "34206/34206 [==============================] - 9s 249us/step - loss: 0.7543 - mean_squared_error: 0.7543 - val_loss: 0.5006 - val_mean_squared_error: 0.5006\n",
      "Epoch 6/30\n",
      "34206/34206 [==============================] - 9s 255us/step - loss: 0.7542 - mean_squared_error: 0.7542 - val_loss: 0.5298 - val_mean_squared_error: 0.5298\n",
      "Epoch 7/30\n",
      "34206/34206 [==============================] - 8s 240us/step - loss: 0.7536 - mean_squared_error: 0.7536 - val_loss: 0.5162 - val_mean_squared_error: 0.5162\n",
      "Epoch 8/30\n",
      "34206/34206 [==============================] - 9s 249us/step - loss: 0.7533 - mean_squared_error: 0.7533 - val_loss: 0.4899 - val_mean_squared_error: 0.4899\n",
      "Epoch 9/30\n",
      "34206/34206 [==============================] - 9s 255us/step - loss: 0.7530 - mean_squared_error: 0.7530 - val_loss: 0.4873 - val_mean_squared_error: 0.4873\n",
      "Epoch 10/30\n",
      "34206/34206 [==============================] - 9s 258us/step - loss: 0.7530 - mean_squared_error: 0.7530 - val_loss: 0.6384 - val_mean_squared_error: 0.6384\n",
      "Epoch 11/30\n",
      "34206/34206 [==============================] - 8s 245us/step - loss: 0.7527 - mean_squared_error: 0.7527 - val_loss: 0.5041 - val_mean_squared_error: 0.5041\n",
      "Epoch 12/30\n",
      "34206/34206 [==============================] - 8s 227us/step - loss: 0.7520 - mean_squared_error: 0.7520 - val_loss: 0.5356 - val_mean_squared_error: 0.5356\n",
      "Epoch 13/30\n",
      "34206/34206 [==============================] - 8s 242us/step - loss: 0.7521 - mean_squared_error: 0.7521 - val_loss: 0.6441 - val_mean_squared_error: 0.6441\n",
      "Epoch 14/30\n",
      "34206/34206 [==============================] - 8s 236us/step - loss: 0.7520 - mean_squared_error: 0.7520 - val_loss: 0.5092 - val_mean_squared_error: 0.5092\n",
      "Epoch 15/30\n",
      "34206/34206 [==============================] - 8s 230us/step - loss: 0.7521 - mean_squared_error: 0.7521 - val_loss: 0.6315 - val_mean_squared_error: 0.6315\n",
      "Epoch 16/30\n",
      "34206/34206 [==============================] - 8s 235us/step - loss: 0.7512 - mean_squared_error: 0.7512 - val_loss: 0.6752 - val_mean_squared_error: 0.6752\n",
      "Epoch 17/30\n",
      "34206/34206 [==============================] - 8s 230us/step - loss: 0.7518 - mean_squared_error: 0.7518 - val_loss: 0.5155 - val_mean_squared_error: 0.5155\n",
      "Epoch 18/30\n",
      "34206/34206 [==============================] - 8s 233us/step - loss: 0.7517 - mean_squared_error: 0.7517 - val_loss: 0.5635 - val_mean_squared_error: 0.5635\n",
      "Epoch 19/30\n",
      "34206/34206 [==============================] - 8s 229us/step - loss: 0.7514 - mean_squared_error: 0.7514 - val_loss: 0.5778 - val_mean_squared_error: 0.5778\n",
      "Epoch 20/30\n",
      "34206/34206 [==============================] - 8s 231us/step - loss: 0.7514 - mean_squared_error: 0.7514 - val_loss: 0.5152 - val_mean_squared_error: 0.5152\n",
      "Epoch 21/30\n",
      "34206/34206 [==============================] - 8s 234us/step - loss: 0.7512 - mean_squared_error: 0.7512 - val_loss: 0.4834 - val_mean_squared_error: 0.4834\n",
      "Epoch 22/30\n",
      "34206/34206 [==============================] - 8s 239us/step - loss: 0.7514 - mean_squared_error: 0.7514 - val_loss: 0.4533 - val_mean_squared_error: 0.4533\n",
      "Epoch 23/30\n",
      "34206/34206 [==============================] - 7s 212us/step - loss: 0.7509 - mean_squared_error: 0.7509 - val_loss: 0.4542 - val_mean_squared_error: 0.4542\n",
      "Epoch 24/30\n",
      "34206/34206 [==============================] - 7s 218us/step - loss: 0.7508 - mean_squared_error: 0.7508 - val_loss: 0.5667 - val_mean_squared_error: 0.5667\n",
      "Epoch 25/30\n",
      "34206/34206 [==============================] - 7s 216us/step - loss: 0.7510 - mean_squared_error: 0.7510 - val_loss: 0.5575 - val_mean_squared_error: 0.5575\n",
      "Epoch 26/30\n",
      "34206/34206 [==============================] - 8s 235us/step - loss: 0.7507 - mean_squared_error: 0.7507 - val_loss: 0.5349 - val_mean_squared_error: 0.5349\n",
      "Epoch 27/30\n",
      "34206/34206 [==============================] - 7s 216us/step - loss: 0.7508 - mean_squared_error: 0.7508 - val_loss: 0.5201 - val_mean_squared_error: 0.5201\n",
      "Epoch 28/30\n",
      "34206/34206 [==============================] - 7s 218us/step - loss: 0.7508 - mean_squared_error: 0.7508 - val_loss: 0.4772 - val_mean_squared_error: 0.4772\n",
      "Epoch 29/30\n",
      "34206/34206 [==============================] - 5s 149us/step - loss: 0.7511 - mean_squared_error: 0.7511 - val_loss: 0.6206 - val_mean_squared_error: 0.6206\n",
      "Epoch 30/30\n",
      "34206/34206 [==============================] - 5s 146us/step - loss: 0.7507 - mean_squared_error: 0.7507 - val_loss: 0.5142 - val_mean_squared_error: 0.5142\n",
      "처리중인 폴드 # 3\n",
      "Train on 34206 samples, validate on 4092 samples\n",
      "Epoch 1/30\n",
      "34206/34206 [==============================] - 14s 417us/step - loss: 0.8334 - mean_squared_error: 0.8334 - val_loss: 0.5517 - val_mean_squared_error: 0.5517\n",
      "Epoch 2/30\n",
      "34206/34206 [==============================] - 8s 222us/step - loss: 0.8033 - mean_squared_error: 0.8033 - val_loss: 0.7189 - val_mean_squared_error: 0.7189\n",
      "Epoch 3/30\n",
      "34206/34206 [==============================] - 7s 202us/step - loss: 0.8037 - mean_squared_error: 0.8037 - val_loss: 0.5694 - val_mean_squared_error: 0.5694\n",
      "Epoch 4/30\n",
      "34206/34206 [==============================] - 8s 227us/step - loss: 0.8034 - mean_squared_error: 0.8034 - val_loss: 0.5740 - val_mean_squared_error: 0.5740\n",
      "Epoch 5/30\n",
      "34206/34206 [==============================] - 7s 204us/step - loss: 0.8032 - mean_squared_error: 0.8032 - val_loss: 0.5571 - val_mean_squared_error: 0.5571\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34206/34206 [==============================] - 9s 254us/step - loss: 0.8029 - mean_squared_error: 0.8029 - val_loss: 0.7523 - val_mean_squared_error: 0.7523\n",
      "Epoch 7/30\n",
      "34206/34206 [==============================] - 9s 268us/step - loss: 0.8027 - mean_squared_error: 0.8027 - val_loss: 0.7070 - val_mean_squared_error: 0.7070\n",
      "Epoch 8/30\n",
      "34206/34206 [==============================] - 10s 307us/step - loss: 0.8020 - mean_squared_error: 0.8020 - val_loss: 0.7803 - val_mean_squared_error: 0.7803\n",
      "Epoch 9/30\n",
      "34206/34206 [==============================] - 10s 284us/step - loss: 0.8015 - mean_squared_error: 0.8015 - val_loss: 0.6876 - val_mean_squared_error: 0.6876\n",
      "Epoch 10/30\n",
      "34206/34206 [==============================] - 10s 282us/step - loss: 0.8013 - mean_squared_error: 0.8013 - val_loss: 0.8278 - val_mean_squared_error: 0.8278\n",
      "Epoch 11/30\n",
      "34206/34206 [==============================] - 11s 309us/step - loss: 0.8013 - mean_squared_error: 0.8013 - val_loss: 0.5843 - val_mean_squared_error: 0.5843\n",
      "Epoch 12/30\n",
      "34206/34206 [==============================] - 10s 280us/step - loss: 0.8013 - mean_squared_error: 0.8013 - val_loss: 0.5172 - val_mean_squared_error: 0.5172\n",
      "Epoch 13/30\n",
      "34206/34206 [==============================] - 10s 284us/step - loss: 0.8004 - mean_squared_error: 0.8004 - val_loss: 0.6866 - val_mean_squared_error: 0.6866\n",
      "Epoch 14/30\n",
      "34206/34206 [==============================] - 9s 271us/step - loss: 0.7996 - mean_squared_error: 0.7996 - val_loss: 0.5120 - val_mean_squared_error: 0.5120\n",
      "Epoch 15/30\n",
      "34206/34206 [==============================] - 10s 284us/step - loss: 0.7998 - mean_squared_error: 0.7998 - val_loss: 0.7233 - val_mean_squared_error: 0.7233\n",
      "Epoch 16/30\n",
      "34206/34206 [==============================] - 11s 307us/step - loss: 0.7995 - mean_squared_error: 0.7995 - val_loss: 0.6342 - val_mean_squared_error: 0.6342\n",
      "Epoch 17/30\n",
      "34206/34206 [==============================] - 9s 275us/step - loss: 0.7992 - mean_squared_error: 0.7992 - val_loss: 0.5119 - val_mean_squared_error: 0.5119\n",
      "Epoch 18/30\n",
      "34206/34206 [==============================] - 10s 285us/step - loss: 0.7987 - mean_squared_error: 0.7987 - val_loss: 0.7836 - val_mean_squared_error: 0.7836\n",
      "Epoch 19/30\n",
      "34206/34206 [==============================] - 10s 290us/step - loss: 0.7984 - mean_squared_error: 0.7984 - val_loss: 0.6647 - val_mean_squared_error: 0.6647\n",
      "Epoch 20/30\n",
      "34206/34206 [==============================] - 9s 275us/step - loss: 0.7984 - mean_squared_error: 0.7984 - val_loss: 0.7193 - val_mean_squared_error: 0.7193\n",
      "Epoch 21/30\n",
      "34206/34206 [==============================] - 11s 312us/step - loss: 0.7983 - mean_squared_error: 0.7983 - val_loss: 0.6462 - val_mean_squared_error: 0.6462\n",
      "Epoch 22/30\n",
      "34206/34206 [==============================] - 8s 239us/step - loss: 0.7984 - mean_squared_error: 0.7984 - val_loss: 0.4748 - val_mean_squared_error: 0.4748\n",
      "Epoch 23/30\n",
      "34206/34206 [==============================] - 9s 272us/step - loss: 0.7985 - mean_squared_error: 0.7985 - val_loss: 0.4978 - val_mean_squared_error: 0.4978\n",
      "Epoch 24/30\n",
      "34206/34206 [==============================] - 10s 297us/step - loss: 0.7976 - mean_squared_error: 0.7976 - val_loss: 0.6771 - val_mean_squared_error: 0.6771\n",
      "Epoch 25/30\n",
      "34206/34206 [==============================] - 9s 271us/step - loss: 0.7978 - mean_squared_error: 0.7978 - val_loss: 0.5280 - val_mean_squared_error: 0.5280\n",
      "Epoch 26/30\n",
      "34206/34206 [==============================] - 11s 309us/step - loss: 0.7972 - mean_squared_error: 0.7972 - val_loss: 0.4639 - val_mean_squared_error: 0.4639\n",
      "Epoch 27/30\n",
      "34206/34206 [==============================] - 9s 269us/step - loss: 0.7979 - mean_squared_error: 0.7979 - val_loss: 0.6415 - val_mean_squared_error: 0.6415\n",
      "Epoch 28/30\n",
      "34206/34206 [==============================] - 9s 267us/step - loss: 0.7970 - mean_squared_error: 0.7970 - val_loss: 0.5411 - val_mean_squared_error: 0.5411\n",
      "Epoch 29/30\n",
      "34206/34206 [==============================] - 10s 290us/step - loss: 0.7976 - mean_squared_error: 0.7976 - val_loss: 0.5466 - val_mean_squared_error: 0.5466\n",
      "Epoch 30/30\n",
      "34206/34206 [==============================] - 9s 272us/step - loss: 0.7970 - mean_squared_error: 0.7970 - val_loss: 0.5614 - val_mean_squared_error: 0.5614\n",
      "처리중인 폴드 # 4\n",
      "Train on 34206 samples, validate on 4092 samples\n",
      "Epoch 1/30\n",
      "34206/34206 [==============================] - 15s 451us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 2/30\n",
      "34206/34206 [==============================] - 8s 248us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 3/30\n",
      "34206/34206 [==============================] - 8s 223us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 4/30\n",
      "34206/34206 [==============================] - 9s 249us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 5/30\n",
      "34206/34206 [==============================] - 8s 234us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 6/30\n",
      "34206/34206 [==============================] - 8s 243us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 7/30\n",
      "34206/34206 [==============================] - 8s 238us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 8/30\n",
      "34206/34206 [==============================] - 8s 232us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 9/30\n",
      "34206/34206 [==============================] - 7s 214us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 10/30\n",
      "34206/34206 [==============================] - 8s 222us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 11/30\n",
      "34206/34206 [==============================] - 7s 218us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 12/30\n",
      "34206/34206 [==============================] - 7s 219us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 13/30\n",
      "34206/34206 [==============================] - 8s 228us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 14/30\n",
      "34206/34206 [==============================] - 8s 225us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 15/30\n",
      "34206/34206 [==============================] - 8s 243us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 16/30\n",
      "34206/34206 [==============================] - 7s 203us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 17/30\n",
      "34206/34206 [==============================] - 7s 213us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 18/30\n",
      "34206/34206 [==============================] - 7s 213us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 19/30\n",
      "34206/34206 [==============================] - 8s 226us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 20/30\n",
      "34206/34206 [==============================] - 8s 223us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 21/30\n",
      "34206/34206 [==============================] - 7s 200us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 22/30\n",
      "34206/34206 [==============================] - 7s 210us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 23/30\n",
      "34206/34206 [==============================] - 8s 232us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34206/34206 [==============================] - 10s 293us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 25/30\n",
      "34206/34206 [==============================] - 10s 296us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 26/30\n",
      "34206/34206 [==============================] - 11s 313us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 27/30\n",
      "34206/34206 [==============================] - 10s 283us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 28/30\n",
      "34206/34206 [==============================] - 10s 296us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 29/30\n",
      "34206/34206 [==============================] - 10s 307us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n",
      "Epoch 30/30\n",
      "34206/34206 [==============================] - 9s 275us/step - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 0.6547 - val_mean_squared_error: 0.6547\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "num_val_samples = len(x_weather) // k\n",
    "num_epochs = 100\n",
    "all_mse_histories = []\n",
    "for i in range(k):\n",
    "    print('처리중인 폴드 #', i)\n",
    "    # 검증 데이터 준비: k번째 분할\n",
    "    val_data_rgb = x_rgb_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_data_w = x_weather[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y_rad[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    \n",
    "    \n",
    "\n",
    "    # 훈련 데이터 준비: 다른 분할 전체\n",
    "    partial_train_data_rgb = np.concatenate([x_rgb_train[:i * num_val_samples],x_rgb_train[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_data_w = np.concatenate([x_weather[:i * num_val_samples],x_weather[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([y_rad[:i * num_val_samples],y_rad[(i + 1) * num_val_samples:]],axis=0)\n",
    "\n",
    "    # 케라스 모델 구성(컴파일 포함)\n",
    "    model = build_model()\n",
    "    # 모델 훈련(verbose=0 이므로 훈련 과정이 출력되지 않습니다)\n",
    "    history=model.fit([partial_train_data_rgb,partial_train_data_w],partial_train_targets,batch_size=100,epochs=30,validation_data=([x_rgb_val,x_weather_val],y_rad_val))\n",
    "    mae_history = history.history['val_loss']\n",
    "    all_mse_histories.append(mae_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7974401757654697,\n",
       " 0.7382089437455065,\n",
       " 0.711279571507615,\n",
       " 0.6843486942845756,\n",
       " 0.675792736296002,\n",
       " 0.7110507338888089,\n",
       " 0.7204032478140692,\n",
       " 0.7083215631158317,\n",
       " 0.7004441004072716,\n",
       " 0.7478263506638638,\n",
       " 0.6750467375819701,\n",
       " 0.6765571161902877,\n",
       " 0.7139621345295512,\n",
       " 0.6679707032672454,\n",
       " 0.7160543981800398,\n",
       " 0.7246357976970601,\n",
       " 0.6774036864444932,\n",
       " 0.7177204923293895,\n",
       " 0.7226647945861471,\n",
       " 0.7001480537328605,\n",
       " 0.6985856065049098,\n",
       " 0.6586599127941937,\n",
       " 0.656304023193343,\n",
       " 0.7051600764954348,\n",
       " 0.6791114919967566,\n",
       " 0.6741059318444309,\n",
       " 0.7002749445825611,\n",
       " 0.6822932421556264,\n",
       " 0.6869659501872222,\n",
       " 0.6799867930705947]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs =30\n",
    "average_mae_history = [np.sqrt(np.mean([x[i] for x in all_mse_histories])) for i in range(num_epochs)]\n",
    "average_mae_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8091603384496372"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_history = history.history['val_loss']\n",
    "np.mean(np.sqrt(mse_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_model(x_rgb_train,y_rad,x_rgb_val,y_rad_val):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(72,1,activation='sigmoid',input_shape=(3,3,3),strides=2))\n",
    "    model.add(Conv2D(36,1,activation='sigmoid',input_shape=(3,3,3)))\n",
    "    model.add(Conv2D(36,1,activation='sigmoid',input_shape=(3,3,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(36,activation='sigmoid')) # 변경가능\n",
    "    model.add(Dense(24,activation='sigmoid')) # 변경가능\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])   \n",
    "    model.summary()\n",
    "    # model.save('paper.h5')\n",
    "\n",
    "\n",
    "    # -----\n",
    "    hist=model.fit(x_rgb_train,y_rad,batch_size=100,epochs=20,validation_data=(x_rgb_val,y_rad_val) ) \n",
    "    #hist=model.fit(x_train,y_train,batch_size=1000,epochs=30 )\n",
    "    # predict부분 구현해야 함   \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_205 (Conv2D)          (None, 2, 2, 72)          288       \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 2, 2, 36)          2628      \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 2, 2, 36)          1332      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling (None, 1, 1, 36)          0         \n",
      "_________________________________________________________________\n",
      "flatten_96 (Flatten)         (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_602 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dense_603 (Dense)            (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "dense_604 (Dense)            (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 6,493\n",
      "Trainable params: 6,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 42757 samples, validate on 4092 samples\n",
      "Epoch 1/20\n",
      "42757/42757 [==============================] - 16s 380us/step - loss: 0.7986 - mean_squared_error: 0.7986 - val_loss: 0.5826 - val_mean_squared_error: 0.5826\n",
      "Epoch 2/20\n",
      "42757/42757 [==============================] - 10s 224us/step - loss: 0.7905 - mean_squared_error: 0.7905 - val_loss: 0.5195 - val_mean_squared_error: 0.5195\n",
      "Epoch 3/20\n",
      "42757/42757 [==============================] - 8s 191us/step - loss: 0.7900 - mean_squared_error: 0.7900 - val_loss: 0.6925 - val_mean_squared_error: 0.6925\n",
      "Epoch 4/20\n",
      "42757/42757 [==============================] - 8s 178us/step - loss: 0.7894 - mean_squared_error: 0.7894 - val_loss: 0.6195 - val_mean_squared_error: 0.6195\n",
      "Epoch 5/20\n",
      "42757/42757 [==============================] - 9s 201us/step - loss: 0.7887 - mean_squared_error: 0.7887 - val_loss: 0.6038 - val_mean_squared_error: 0.6038\n",
      "Epoch 6/20\n",
      "42757/42757 [==============================] - 8s 188us/step - loss: 0.7877 - mean_squared_error: 0.7877 - val_loss: 0.7144 - val_mean_squared_error: 0.7144\n",
      "Epoch 7/20\n",
      "42757/42757 [==============================] - 9s 205us/step - loss: 0.7875 - mean_squared_error: 0.7875 - val_loss: 0.6095 - val_mean_squared_error: 0.6095\n",
      "Epoch 8/20\n",
      "42757/42757 [==============================] - 8s 178us/step - loss: 0.7872 - mean_squared_error: 0.7872 - val_loss: 0.5103 - val_mean_squared_error: 0.5103\n",
      "Epoch 9/20\n",
      "42757/42757 [==============================] - 8s 193us/step - loss: 0.7871 - mean_squared_error: 0.7871 - val_loss: 0.6090 - val_mean_squared_error: 0.6090\n",
      "Epoch 10/20\n",
      "42757/42757 [==============================] - 7s 162us/step - loss: 0.7871 - mean_squared_error: 0.7871 - val_loss: 0.6544 - val_mean_squared_error: 0.6544\n",
      "Epoch 11/20\n",
      "42757/42757 [==============================] - 8s 182us/step - loss: 0.7867 - mean_squared_error: 0.7867 - val_loss: 0.6030 - val_mean_squared_error: 0.6030\n",
      "Epoch 12/20\n",
      "42757/42757 [==============================] - 8s 197us/step - loss: 0.7864 - mean_squared_error: 0.7864 - val_loss: 0.5766 - val_mean_squared_error: 0.5766\n",
      "Epoch 13/20\n",
      "42757/42757 [==============================] - 8s 190us/step - loss: 0.7862 - mean_squared_error: 0.7862 - val_loss: 0.7469 - val_mean_squared_error: 0.7469\n",
      "Epoch 14/20\n",
      "42757/42757 [==============================] - 8s 182us/step - loss: 0.7868 - mean_squared_error: 0.7868 - val_loss: 0.6256 - val_mean_squared_error: 0.6256\n",
      "Epoch 15/20\n",
      "42757/42757 [==============================] - 9s 209us/step - loss: 0.7865 - mean_squared_error: 0.7865 - val_loss: 0.5214 - val_mean_squared_error: 0.5214\n",
      "Epoch 16/20\n",
      "42757/42757 [==============================] - 9s 201us/step - loss: 0.7868 - mean_squared_error: 0.7868 - val_loss: 0.6024 - val_mean_squared_error: 0.6024\n",
      "Epoch 17/20\n",
      "42757/42757 [==============================] - 8s 187us/step - loss: 0.7865 - mean_squared_error: 0.7865 - val_loss: 0.6787 - val_mean_squared_error: 0.6787\n",
      "Epoch 18/20\n",
      "42757/42757 [==============================] - 8s 191us/step - loss: 0.7865 - mean_squared_error: 0.7865 - val_loss: 0.7188 - val_mean_squared_error: 0.7188\n",
      "Epoch 19/20\n",
      "42757/42757 [==============================] - 7s 173us/step - loss: 0.7860 - mean_squared_error: 0.7860 - val_loss: 0.6978 - val_mean_squared_error: 0.6978\n",
      "Epoch 20/20\n",
      "42757/42757 [==============================] - 8s 188us/step - loss: 0.7857 - mean_squared_error: 0.7857 - val_loss: 0.6596 - val_mean_squared_error: 0.6596\n"
     ]
    }
   ],
   "source": [
    "hist=paper_model(x_rgb_train,y_rad,x_rgb_val,y_rad_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7909158461246398"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_history = hist.history['val_loss']\n",
    "np.mean(np.sqrt(mse_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 월구분,stn구분은 해서 비교표를 결과로 넣을 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_model(x_rgb_train,y_rad,x_rgb_val,y_rad_val):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(72,1,activation='sigmoid',input_shape=(3,3,3),strides=2))\n",
    "    model.add(Conv2D(36,1,activation='sigmoid',input_shape=(3,3,3)))\n",
    "    model.add(Conv2D(36,1,activation='sigmoid',input_shape=(3,3,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(36,activation='sigmoid')) # 변경가능\n",
    "    model.add(Dense(24,activation='sigmoid')) # 변경가능\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['mse'])   \n",
    "    model.summary()\n",
    "    # model.save('paper.h5')\n",
    "\n",
    "\n",
    "    # -----\n",
    "    hist=model.fit(x_rgb_train,y_rad,batch_size=100,epochs=20,validation_data=(x_rgb_val,y_rad_val) ) \n",
    "    #hist=model.fit(x_train,y_train,batch_size=1000,epochs=30 )\n",
    "    # predict부분 구현해야 함   \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_178 (Conv2D)          (None, 2, 2, 72)          288       \n",
      "_________________________________________________________________\n",
      "conv2d_179 (Conv2D)          (None, 2, 2, 36)          2628      \n",
      "_________________________________________________________________\n",
      "conv2d_180 (Conv2D)          (None, 2, 2, 36)          1332      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_87 (MaxPooling (None, 1, 1, 36)          0         \n",
      "_________________________________________________________________\n",
      "flatten_87 (Flatten)         (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_547 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dense_548 (Dense)            (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "dense_549 (Dense)            (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 6,493\n",
      "Trainable params: 6,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 42757 samples, validate on 4092 samples\n",
      "Epoch 1/20\n",
      "42757/42757 [==============================] - 15s 342us/step - loss: 0.7918 - mean_squared_error: 0.7918 - val_loss: 0.6649 - val_mean_squared_error: 0.6649\n",
      "Epoch 2/20\n",
      "42757/42757 [==============================] - 8s 179us/step - loss: 0.7898 - mean_squared_error: 0.7898 - val_loss: 0.5778 - val_mean_squared_error: 0.5778\n",
      "Epoch 3/20\n",
      "42757/42757 [==============================] - 8s 179us/step - loss: 0.7893 - mean_squared_error: 0.7893 - val_loss: 0.6337 - val_mean_squared_error: 0.6337\n",
      "Epoch 4/20\n",
      "42757/42757 [==============================] - 7s 166us/step - loss: 0.7885 - mean_squared_error: 0.7885 - val_loss: 0.6078 - val_mean_squared_error: 0.6078\n",
      "Epoch 5/20\n",
      "42757/42757 [==============================] - 7s 168us/step - loss: 0.7882 - mean_squared_error: 0.7882 - val_loss: 0.5816 - val_mean_squared_error: 0.5816\n",
      "Epoch 6/20\n",
      "42757/42757 [==============================] - 8s 180us/step - loss: 0.7877 - mean_squared_error: 0.7877 - val_loss: 0.6427 - val_mean_squared_error: 0.6427\n",
      "Epoch 7/20\n",
      "42757/42757 [==============================] - 8s 190us/step - loss: 0.7872 - mean_squared_error: 0.7872 - val_loss: 0.6152 - val_mean_squared_error: 0.6152\n",
      "Epoch 8/20\n",
      "42757/42757 [==============================] - 7s 171us/step - loss: 0.7867 - mean_squared_error: 0.7867 - val_loss: 0.6209 - val_mean_squared_error: 0.6209\n",
      "Epoch 9/20\n",
      "42757/42757 [==============================] - 7s 175us/step - loss: 0.7863 - mean_squared_error: 0.7863 - val_loss: 0.6034 - val_mean_squared_error: 0.6034\n",
      "Epoch 10/20\n",
      "42757/42757 [==============================] - 7s 162us/step - loss: 0.7858 - mean_squared_error: 0.7858 - val_loss: 0.6429 - val_mean_squared_error: 0.6429\n",
      "Epoch 11/20\n",
      "42757/42757 [==============================] - 6s 151us/step - loss: 0.7855 - mean_squared_error: 0.7855 - val_loss: 0.6048 - val_mean_squared_error: 0.6048\n",
      "Epoch 12/20\n",
      "42757/42757 [==============================] - 9s 215us/step - loss: 0.7849 - mean_squared_error: 0.7849 - val_loss: 0.6514 - val_mean_squared_error: 0.6514\n",
      "Epoch 13/20\n",
      "42757/42757 [==============================] - 7s 172us/step - loss: 0.7847 - mean_squared_error: 0.7847 - val_loss: 0.6023 - val_mean_squared_error: 0.6023\n",
      "Epoch 14/20\n",
      "42757/42757 [==============================] - 8s 176us/step - loss: 0.7846 - mean_squared_error: 0.7846 - val_loss: 0.5820 - val_mean_squared_error: 0.5820\n",
      "Epoch 15/20\n",
      "42757/42757 [==============================] - 7s 175us/step - loss: 0.7845 - mean_squared_error: 0.7845 - val_loss: 0.6076 - val_mean_squared_error: 0.6076\n",
      "Epoch 16/20\n",
      "42757/42757 [==============================] - 8s 179us/step - loss: 0.7842 - mean_squared_error: 0.7842 - val_loss: 0.7124 - val_mean_squared_error: 0.7124\n",
      "Epoch 17/20\n",
      "42757/42757 [==============================] - 7s 167us/step - loss: 0.7838 - mean_squared_error: 0.7838 - val_loss: 0.5676 - val_mean_squared_error: 0.5676\n",
      "Epoch 18/20\n",
      "42757/42757 [==============================] - 7s 168us/step - loss: 0.7838 - mean_squared_error: 0.7838 - val_loss: 0.6734 - val_mean_squared_error: 0.6734\n",
      "Epoch 19/20\n",
      "42757/42757 [==============================] - 7s 153us/step - loss: 0.7839 - mean_squared_error: 0.7839 - val_loss: 0.6128 - val_mean_squared_error: 0.6128\n",
      "Epoch 20/20\n",
      "42757/42757 [==============================] - 7s 156us/step - loss: 0.7839 - mean_squared_error: 0.7839 - val_loss: 0.5913 - val_mean_squared_error: 0.5913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7869787169201123"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist=paper_model(x_rgb_train,y_rad,x_rgb_val,y_rad_val)\n",
    "mse_history = hist.history['val_loss']\n",
    "np.mean(np.sqrt(mse_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " # 정확도를 위해서는 월별로, 지점별로 테스트 해봐야할것 같다.\n",
    "\n",
    "hist_dict=hist.history\n",
    "hist_dict.keys()\n",
    "\n",
    "val_loss= hist_dict['val_loss']\n",
    "loss = hist_dict['loss']\n",
    "epochs =range(1,len(loss)+1)\n",
    "\n",
    "plt.plot(epochs,loss,'bo-',label='Training loss')\n",
    "plt.plot(epochs,val_loss,'r^-',label='val loss')\n",
    "\n",
    "plt.title('loss graph, Nov, 18h')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
